{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Use \"high-ram\""
      ],
      "metadata": {
        "id": "RKmhZAigP4cb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gpxsp9ixrjIa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from itertools import chain\n",
        "from functools import reduce"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"../full_v5_text.csv\", lineterminator = '\\n')"
      ],
      "metadata": {
        "id": "O8XuP8Gqrw4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_dataframe(df):\n",
        "    # Extract the year and year-month from the 'created_at' column\n",
        "    df[\"year\"] = df[\"created_at\"].str[:4]\n",
        "    df[\"year-month\"] = df[\"created_at\"].str[:10]\n",
        "\n",
        "    # Define a dictionary to map category names to numeric values\n",
        "    cat_dict = {'Positive': 10, 'Neutral': 0, 'Negative': -10}\n",
        "\n",
        "    # Map the category names to numeric values using the dictionary\n",
        "    df[\"category_num\"] = df[\"category_pred\"].map(cat_dict)\n",
        "\n",
        "    # Select and reorder columns\n",
        "    df = df[['tweet_id', 'text', \"category_pred\", 'category_num', 'created_at', 'user_id',\n",
        "             'user_loc', 'like_count', 'retweet_count', 'GEO_ID', 'STATE_FIPS', 'year',\n",
        "             'year-month']]\n",
        "\n",
        "    return df\n",
        "\n",
        "df = preprocess_dataframe(df)"
      ],
      "metadata": {
        "id": "b8E9Os5wNkdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['category_num'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ln3P-4mZNkv-",
        "outputId": "f8b2b8a9-7320-4793-ea00-599a7cc86d53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 10    5154974\n",
              " 0     1824577\n",
              "-10    1044958\n",
              "Name: category_num, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Datasets by States and Cities"
      ],
      "metadata": {
        "id": "SPp01ltId2bb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def aggregate_byyear_bygeography(df, year, geography):\n",
        "    df_year = df.loc[df[\"year\"] == year]\n",
        "\n",
        "    # Group by user_id and compute the mean and count of the category_num column\n",
        "    id_grouped = df_year.groupby('user_id').agg({'category_num': ['mean', 'count'], geography: 'last'})\n",
        "\n",
        "    # Rename the columns\n",
        "    id_grouped.columns = ['score_mean', 'tweet_count', geography]\n",
        "\n",
        "    id_grouped.reset_index(inplace=True)\n",
        "\n",
        "    # Group by geography and get the number of tweets and unique user IDs\n",
        "    year_id_grouped = id_grouped.groupby(geography).agg({'score_mean': ['mean'], 'tweet_count':['sum'], 'user_id': ['count']})\n",
        "\n",
        "    # Rename the columns\n",
        "    year_id_grouped.columns = ['sent_score', 'tweet_count', 'user_count']\n",
        "\n",
        "    year_id_grouped = year_id_grouped.reset_index().rename(columns={'index': geography})\n",
        "\n",
        "    # Add the 'year' column\n",
        "    year_id_grouped['year'] = year\n",
        "\n",
        "    # NaN columns removed if any\n",
        "    year_id_grouped = year_id_grouped[year_id_grouped.user_count >= 1]\n",
        "\n",
        "    # Sort the DataFrame by 'user_count'\n",
        "    year_id_grouped = year_id_grouped.sort_values(by='user_count', ascending=False)\n",
        "\n",
        "    # Select specific columns\n",
        "    year_id_grouped = year_id_grouped[[geography, 'year', 'sent_score', 'tweet_count', 'user_count']]\n",
        "\n",
        "    year_id_grouped = year_id_grouped.reset_index(drop=True)\n",
        "\n",
        "    return year_id_grouped"
      ],
      "metadata": {
        "id": "AUHR7ydGYwfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cities"
      ],
      "metadata": {
        "id": "lLN7dDM1UjgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the list of years\n",
        "years = [\"2013\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\", \"2020\", \"2021\", \"2022\"]"
      ],
      "metadata": {
        "id": "tPMxUTi2ZSyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty DataFrame to store the results\n",
        "df_byyear_bycity = pd.DataFrame()\n",
        "\n",
        "geography = \"GEO_ID\"\n",
        "\n",
        "# Process each year and concatenate the results\n",
        "for year in years:\n",
        "    year_data = aggregate_byyear_bygeography(df, year, geography)\n",
        "    df_byyear_bycity = pd.concat([df_byyear_bycity, year_data], ignore_index=True)\n",
        "\n",
        "df_byyear_bycity.to_csv(\"../sent_allyears_allcities_v6.csv\", index=False)"
      ],
      "metadata": {
        "id": "KI8jxsN_Y3PO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# States"
      ],
      "metadata": {
        "id": "9tO0hzu7es17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_byyear_bystate = pd.DataFrame()\n",
        "\n",
        "geography = \"STATE_FIPS\"\n",
        "\n",
        "# Process each year and concatenate the results\n",
        "for year in years:\n",
        "    year_data = aggregate_byyear_bygeography(df, year, geography)\n",
        "    df_byyear_bystate = pd.concat([df_byyear_bystate, year_data], ignore_index=True)\n",
        "\n",
        "# Save the final DataFrame to a CSV file\n",
        "df_byyear_bystate.to_csv(\"../sent_allyears_allstates_v6.csv\", index=False)"
      ],
      "metadata": {
        "id": "RMJZOxqxQ-kE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_byyear_bystate.tweet_count.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aK7GUEIAfN_g",
        "outputId": "068a84ef-90ab-4f46-93ba-ee06f3ca00d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8024509"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    }
  ]
}