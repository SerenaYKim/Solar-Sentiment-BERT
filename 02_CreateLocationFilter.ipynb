{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "def load_state_fips():\n",
        "    statefips = pd.read_csv(\"../statefips.csv\")\n",
        "    return statefips[\"STATE_FIPS\"].tolist()"
      ],
      "metadata": {
        "id": "haFr1ZdquUa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_census_data_tableS(api_key, geography, colnamedict, years, var):\n",
        "    HOST = 'https://api.census.gov/data/'\n",
        "    data = f\"/acs/acs5/subject?get=group({var})\"\n",
        "\n",
        "    coloutput = [i for i in colnamedict.values()]\n",
        "    colinput = [i for i in colnamedict.keys()]\n",
        "    featurelist = coloutput[1:]\n",
        "    default = [\"state\", \"place\", \"NAME\", \"year\", \"fips\"]\n",
        "    varnames = coloutput + default\n",
        "\n",
        "    df = pd.DataFrame()\n",
        "\n",
        "    for year in years:\n",
        "        url = HOST + year + data + '&for=' + geography + \":*&in=state:*\" + \"&in=county:*&key=\" + api_key\n",
        "        resp = requests.get(url)\n",
        "        unit = resp.json()\n",
        "        df1 = pd.DataFrame(unit[1:], columns=unit[0])\n",
        "        df1[\"year\"] = year\n",
        "        df = pd.concat([df, df1])\n",
        "\n",
        "    df.rename(columns=colnamedict, inplace=True)\n",
        "    df[\"fips\"] = df[\"GEO_ID\"].str[9:].apply(int)\n",
        "    df = df[varnames]\n",
        "\n",
        "    for feature in featurelist:\n",
        "        df.loc[df[feature] == \"-666666666\", feature] = \" \"\n",
        "        df.loc[df[feature] == \"-\", feature] = \" \"\n",
        "\n",
        "    for feature in featurelist:\n",
        "        df[feature] = pd.to_numeric(df[feature].str.replace(\" \", \"\"), errors='coerce')\n",
        "        df[feature] = df[feature].astype('Int64')\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "cBmYagnXxKmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_census_data_tableB(api_key, geography, colnamedict, years):\n",
        "    HOST = 'https://api.census.gov/data/'\n",
        "    data = '/acs/acs5?get=' #ACS 5-Year Estimates Detailed Tables\n",
        "\n",
        "    # output variables (variable names to be recorded in csv files)\n",
        "    coloutput = [i for i in colnamedict.values()]\n",
        "\n",
        "    # input variables (US Census code)\n",
        "    colinput = [i for i in colnamedict.keys()]\n",
        "\n",
        "    # feature names except for the \"GEO_ID\"\n",
        "    featurelist = coloutput[1:]\n",
        "    varnames = coloutput\n",
        "\n",
        "    df = pd.DataFrame()\n",
        "\n",
        "    for year in years:\n",
        "        url = HOST + year + data + ','.join(colinput) + '&for=' + geography + \":*&in=state:*\" + \"&in=county:*&key=\" + api_key\n",
        "        resp = requests.get(url)\n",
        "        unit = resp.json()\n",
        "        df1 = pd.DataFrame(unit[1:], columns=unit[0])\n",
        "        df1[\"year\"] = year\n",
        "        df = pd.concat([df, df1], ignore_index=True)\n",
        "\n",
        "    df.rename(columns=colnamedict, inplace=True)\n",
        "    df[\"fips\"] = df[\"GEO_ID\"].str[9:].apply(int)\n",
        "    df = df[varnames]\n",
        "\n",
        "    for feature in featurelist:\n",
        "        df.loc[df[feature]== \"-666666666\", feature] = \" \"\n",
        "        df.loc[df[feature]== \"-666666666.0\", feature] = \" \"\n",
        "        df.loc[df[feature]== \"-999999999\", feature] = \" \"\n",
        "        df.loc[df[feature]== \"-999999999.0\", feature] = \" \"\n",
        "        df.loc[df[feature]== \"-\", feature] = \" \"\n",
        "\n",
        "    for feature in featurelist:\n",
        "        df[feature] = pd.to_numeric(df[feature].str.replace(\" \", \"\"), errors='coerce')\n",
        "        df[feature] = df[feature].astype('float')\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "0RTZPXIM4Msp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    api_key = \"Your API KEY\"\n",
        "    geography = \"place\"\n",
        "    years = [\"2018\"]\n",
        "    var_S = \"S1903\"  # income\n",
        "\n",
        "    # Column name dictionaries for Table S and Table B\n",
        "    tableS_colnamedict = {\n",
        "        \"GEO_ID\": \"GEO_ID\",\n",
        "        \"S1903_C03_015E\": \"MHIncome\"\n",
        "    }\n",
        "\n",
        "    tableB_colnamedict = {\n",
        "        \"GEO_ID\": \"GEO_ID\",\n",
        "        \"B15003_001E\": \"Population\"\n",
        "    }\n",
        "\n",
        "    state_fips_list = load_state_fips()\n",
        "\n",
        "    # Fetch census data for Table S and Table B\n",
        "    df_census_dataS = fetch_census_data_tableS(api_key, geography, tableS_colnamedict, years, var_S)\n",
        "    df_census_dataB = fetch_census_data_tableB(api_key, geography, tableB_colnamedict, years)\n",
        "\n",
        "    # Merge df_census_dataS and df_census_dataB on the 'GEO_ID' column\n",
        "    merged_df = pd.merge(df_census_dataS, df_census_dataB, on=\"GEO_ID\", how='inner')\n",
        "\n",
        "    # Exclude Puerto Rico (state code 72) and Virgin Islands (state code 78)\n",
        "    df_place = merged_df[~merged_df.state.isin([\"72\", \"78\"])]\n",
        "\n",
        "    # Drop rows with missing values in MHIncome and Population columns\n",
        "    df_place = df_place.dropna(subset=[\"MHIncome\", \"Population\"])\n",
        "\n",
        "    df_place = df_place.sort_values(by=[\"Population\"], ascending=False, ignore_index=True)\n",
        "\n",
        "    return df_place"
      ],
      "metadata": {
        "id": "FybjlYN86wtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    df_result = main()\n",
        "    df_result"
      ],
      "metadata": {
        "id": "UzCK9cdc8u58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_place_100 = df_result[df_result[\"Population\"] >= 100]\n",
        "df_place_100.to_csv(\"../us-place-over100pop.csv\", index=False)"
      ],
      "metadata": {
        "id": "yeDXy1b0t_We"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}