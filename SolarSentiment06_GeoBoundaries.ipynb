{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install geopandas"
      ],
      "metadata": {
        "id": "yGd-wJ8ONd_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bxBffFJqhWL"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re\n",
        "import requests\n",
        "import os\n",
        "import geopandas as gpd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_cnty = r'https://www2.census.gov/geo/tiger/TIGER2019/CBSA/tl_2019_us_cbsa.zip'\n",
        "cnty = gpd.read_file(url_cnty)"
      ],
      "metadata": {
        "id": "HVj8r-G0Bqzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_zip(url):\n",
        "    front_page = requests.get(url,verify=False)\n",
        "    soup = BeautifulSoup(front_page.content,'html.parser')\n",
        "    zf = soup.find_all(\"a\",href=re.compile(r\"zip\"))\n",
        "    # Maybe should use href\n",
        "    zl = [os.path.join(url,i['href']) for i in zf]\n",
        "    return zl"
      ],
      "metadata": {
        "id": "4hlMLgs8LJOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_url = r'https://www2.census.gov/geo/tiger/TIGER2020/PLACE/'\n",
        "res = get_zip(base_url)\n",
        "\n",
        "geo_place = []\n",
        "for surl in res:\n",
        "    geo_place.append(gpd.read_file(surl))\n",
        "\n",
        "geo_full = pd.concat(geo_place)"
      ],
      "metadata": {
        "id": "JbYbNvGGNHkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "geo_full.to_file(\"../tl_2021_us_place.geojson\", driver=\"GeoJSON\")"
      ],
      "metadata": {
        "id": "LVo9T8MdPAce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnty = gpd.read_file(\"/content/drive/MyDrive/G00-place/geo_tiger_bdry/US/tl_2021_us_county/tl_2021_us_county.shp\")\n",
        "cnty"
      ],
      "metadata": {
        "id": "G791OilmLP9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cities_cnty = sent_places.sjoin(cnty, how=\"right\")\n",
        "cities_cnty"
      ],
      "metadata": {
        "id": "5xtrcSN0O0HM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reference\n",
        "\n",
        "https://andrewpwheeler.com/2022/02/28/downloading-geo-files-from-census-ftp-using-python/"
      ],
      "metadata": {
        "id": "qPq9HbzPLK2U"
      }
    }
  ]
}